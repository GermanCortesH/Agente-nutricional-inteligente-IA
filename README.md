# ðŸ¥— Agente Nutricional Inteligente (IA RAG)

## âœ¨ VisiÃ³n General del Proyecto

Este proyecto implementa un agente de Inteligencia Artificial capaz de generar **planes y recomendaciones nutricionales personalizadas** en tiempo real. Utiliza la arquitectura **RAG (Retrieval-Augmented Generation)** con **LangChain** y **ChromaDB** para consultar una base de datos de recetas (*Knowledge Base*) antes de formular una respuesta con el modelo de lenguaje grande (LLM) **Llama 3** (a travÃ©s de Ollama).

El objetivo es ofrecer planes dietÃ©ticos basados en parÃ¡metros especÃ­ficos del usuario (calorÃ­as, proteÃ­nas, grasas, carbohidratos) y datos reales, garantizando respuestas informadas y precisas.

-----

## ðŸš€ CaracterÃ­sticas Clave

  * **GeneraciÃ³n Aumentada (RAG):** El agente consulta una base de datos de recetas indexada en **ChromaDB** antes de generar la respuesta. Esto asegura que las recomendaciones sean factibles y especÃ­ficas.
  * **Agente Conversacional:** Utiliza el framework **LangChain** para orquestar el flujo de trabajo entre la base de datos, el LLM y la herramienta de bÃºsqueda.
  * **Base de Conocimiento:** Utiliza un *dataset* de recetas para construir la base de vectores, permitiendo al agente "recordar" las propiedades nutricionales de los alimentos.
  * **TecnologÃ­a LLM:** Implementado con el modelo **Llama 3** a travÃ©s de **Ollama** para el despliegue local y eficiente.
  * **Interfaz Web:** Desarrollado con **Streamlit** para una interacciÃ³n sencilla e intuitiva con el usuario.

-----

## âš™ï¸ Arquitectura del Sistema

El proyecto sigue un flujo RAG estÃ¡ndar de IA generativa:

1.  **Carga y Preprocesamiento:** Se carga un archivo de datos (ej: `epi_r.csv`).
2.  **Embeddings:** Se generan vectores (embeddings) de los tÃ­tulos de las recetas usando **HuggingFace Embeddings**.
3.  **Vector Store (ChromaDB):** Los embeddings se almacenan en **ChromaDB** para una bÃºsqueda rÃ¡pida.
4.  **Consulta (LangChain/RetrievalQA):** Cuando el usuario pregunta, LangChain recupera las recetas mÃ¡s relevantes de ChromaDB.
5.  **GeneraciÃ³n (Ollama/Llama 3):** El LLM recibe la pregunta original + las recetas recuperadas (contexto) y genera el plan nutricional personalizado.

-----

## ðŸ’» InstalaciÃ³n y EjecuciÃ³n Local

Sigue estos pasos para levantar el proyecto en tu mÃ¡quina.

### Prerrequisitos

1.  **Python 3.9+**

2.  **Ollama:** AsegÃºrate de tener **Ollama** instalado y corriendo, con el modelo `llama3:8b-instruct-q4_0` descargado.

    ```bash
    ollama pull llama3:8b-instruct-q4_0
    ```

### Pasos

1.  **Clonar el Repositorio:**

    ```bash
    git clone https://github.com/GermanCortesH/Agente-nutricional-inteligente-IA.git
    cd Agente-nutricional-inteligente-IA
    ```

2.  **Crear y Activar el Entorno Virtual:**

    ```bash
    python -m venv entorno_ia
    # Windows:
    .\entorno_ia\Scripts\activate
    # Linux/macOS:
    source entorno_ia/bin/activate
    ```

3.  **Instalar Dependencias:**

    ```bash
    pip install -r requirements.txt
    ```

4.  **Ejecutar la AplicaciÃ³n Streamlit:**

    ```bash
    streamlit run App.py
    ```

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en tu navegador. Al iniciar por primera vez, se crearÃ¡ la base de datos `chroma_db/`.

-----

## ðŸ¤ Contribuciones

Si tienes sugerencias para mejorar el *prompt*, aÃ±adir mÃ¡s herramientas o incluir bases de datos mÃ¡s grandes, Â¡tus contribuciones son bienvenidas\!

1.  Haz un `Fork` del repositorio.
2.  Crea una nueva rama (`git checkout -b feature/nueva-funcionalidad`).
3.  Confirma tus cambios (`git commit -m 'feat: AÃ±adir mejora X'`).
4.  Haz `Push` a tu rama (`git push origin feature/nueva-funcionalidad`).
5.  Abre un `Pull Request`.

-----

> Creado por **[German Cortes H.]**
